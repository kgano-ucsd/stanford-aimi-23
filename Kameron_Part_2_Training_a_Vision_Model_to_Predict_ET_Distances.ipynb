{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## AIMI High School Internship 2023\n",
        "### Notebook 2: Training a Vision Model to Predict ET Distances\n",
        "\n",
        "**The Problem**: Given a chest X-ray, our goal in this project is to predict the distance from an endotracheal tube to the carina. This is an important clinical task - endotracheal tubes that are positioned too far (>5cm) above the carina will not work effectively.\n",
        "\n",
        "**Your Second Task**: You should now have a training dataset consisting of (a) chest X-rays and (b) annotations indicating the distance of the endotracheal tube from the carina. Now, your goal is to train a computer vision model to predict endotracheal tube distance from the image. You have **two options** for this task, and you may attempt one or both of these:\n",
        "- *Distance Categorization* : Train a model to determine whether the position of a tube is abnormal (>5.0 cm) or normal (â‰¤ 5.0 cm).\n",
        "- *Distance Prediction*: Train a model that predicts the distance of the endotracheal tube from the carina in centimeters.\n",
        "\n",
        "In this notebook, we provide some simple starter code to get you started on training a computer vision model. You are not required to use this template - feel free to modify as you see fit.\n",
        "\n",
        "**Submitting Your Model**: We have created a leaderboard where you can submit your model and view results on the held-out test set. We provide instructions below for submitting your model to the leaderboard. **Please follow these directions carefully**.\n",
        "\n",
        "We will evaluate your results on the held-out test set with the following evaluation metrics:\n",
        "- *Distance Categorization* : We will measure AUROC, which is a metric commonly used in healthcare tasks. See this blog for a good explanation of AUROC: https://glassboxmedicine.com/2019/02/23/measuring-performance-auc-auroc/\n",
        "- *Distance Prediction*: We will measure the mean average error (also known as L1 distance) between the predicted distances and the true distances.\n"
      ],
      "metadata": {
        "id": "uMfGLGNLnXk7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Data\n",
        "Before you begin, make sure to go to `Runtime` > `Change Runtime Type` and select a T4 GPU. Then, upload `data.zip`. It should take about 10 minutes for these files to be uploaded. Then, run the following cells to unzip the dataset (which should take < 10 seconds)"
      ],
      "metadata": {
        "id": "RJ1rTMrgpoil"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -qq /content/data.zip"
      ],
      "metadata": {
        "id": "ytMQzLJindpR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -qq /content/mimic-train.zip"
      ],
      "metadata": {
        "id": "ySb9AsmBp-Gz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -qq /content/mimic-test.zip"
      ],
      "metadata": {
        "id": "Bqeesviqp_hN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Libraries\n",
        "We are leveraging the PyTorch framework to train our models. For more information and tutorials on PyTorch, see this link: https://pytorch.org/tutorials/beginner/basics/intro.html"
      ],
      "metadata": {
        "id": "q5etX4eYtu_s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Some libraries that you may find useful are included here.\n",
        "# To import a library that isn't provided with Colab, use the following command: !pip install torchmetrics\n",
        "import torch\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n"
      ],
      "metadata": {
        "id": "BzhTFDi7tuPK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Dataloaders\n",
        "We will implement a custom Dataset class to load in data. A custom Dataset class must have three methods: `__init__`, which sets up any class variables, `__len__`, which defines the total number of images, and `__getitem__`, which returns a single image and its paired label."
      ],
      "metadata": {
        "id": "QY7yvIM0yl4M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class ChestXRayDataset(Dataset):\n",
        "    def __init__(self):\n",
        "        super(ChestXRayDataset, self).__init__(**kwargs)\n",
        "\n",
        "        # Fill in __init__() here\n",
        "\n",
        "    def __len__(self):\n",
        "\n",
        "        # Fill in __len__() here\n",
        "        return length\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        out_dict = {\"idx\": torch.tensor(idx),}\n",
        "\n",
        "        # Fill in __getitem__() here\n",
        "\n",
        "        out_dict[\"img\"] = img\n",
        "        out_dict[\"label\"] = label\n",
        "\n",
        "        return out_dict"
      ],
      "metadata": {
        "id": "FwH5586UqAnY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Training Components\n",
        "Here, define any necessary components that you need to train your model, such as the model architecture, the loss function, and the optimizer."
      ],
      "metadata": {
        "id": "2oGRC8Mk0ytJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss = # Loss Function\n",
        "model = # Model Architecture (make sure to load the model on GPU, not CPU!)\n",
        "opt = torch.optim.AdamW(model.parameters(), lr=1e-4) # AdamW is a commonly-used optimizer. Feel free to modify.\n",
        "\n",
        "\n",
        "dataset = ChestXRayDataset(\"\"\" Fill in args here \"\"\")\n",
        "dataloader = torch.utils.data.DataLoader(dataset=dataset, batch_size=\"\"\"Customize batch size\"\"\", shuffle=True, drop_last=True)\n"
      ],
      "metadata": {
        "id": "-HeB-_-k0x_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Code\n",
        "We provide starter code below that implements a simple training loop in PyTorch. Feel free to modify as you see fit."
      ],
      "metadata": {
        "id": "TXvOaNPB1OGH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, loss_fn, train_loader, opt, max_epoch):\n",
        "\n",
        "    best_val_loss = np.inf\n",
        "    best_val_metrics = []\n",
        "    for epoch in range(0, max_epoch):\n",
        "        model.train()\n",
        "\n",
        "        for step, sample in tqdm(enumerate(train_loader)):\n",
        "            opt.zero_grad()\n",
        "            pred = # Compute prediction\n",
        "\n",
        "            loss = # Compute Loss\n",
        "\n",
        "            loss.backward()\n",
        "            opt.step()"
      ],
      "metadata": {
        "id": "pWnzKime0exc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(model, loss, train_loader, opt, max_epoch=5)"
      ],
      "metadata": {
        "id": "yWl9WNpX454H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Submitting Your Results\n",
        "Once you have successfully trained your model, generate predictions on the test set and save your results as a `.csv` file. This file can then be uploaded to the leaderboard.\n",
        "\n",
        "Your final `.csv` file **must** have the following format:\n",
        "- There must be a column titled `image_path` with the paths to the test set images. This column should be identical to the one provided in `mimic_test_student.csv`.\n",
        "- There must be a column titled `pred` with your model outputs.\n",
        "  - If you are running the `distance categorization` task, this column must have floating point numbers ranging between 0 and 1. Higher numbers should indicate a greater likelihood that the tube distance is abnormal. Hint: You can convert model outputs to the 0 to 1 range by applying the sigmoid activation function (torch.nn.sigmoid())\n",
        "  - If you are running the `distance prediction` task, this column must have numbers representing the tube distance in centimeters.\n",
        "- Double check that there are 500 rows in your output file"
      ],
      "metadata": {
        "id": "l8F_1wzY6I7j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = # Model Architecture\n",
        "ckpt = torch.load(\"/content/best.pkl\")\n",
        "model.load_state_dict(ckpt[\"state_dict\"])\n",
        "\n",
        "test_dataset = ChestXRayDataset(\"\"\"Fill in args here\"\"\")\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=4, shuffle=False, drop_last=False)\n",
        "\n",
        "test_results = {\"image_path\": [], \"pred\": []}\n",
        "# Write method to load in data from test_loader, compute model predictions, and append results to test_results dict\n"
      ],
      "metadata": {
        "id": "M5osagFf5Fox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_results = pd.DataFrame(test_results)\n",
        "test_results.to_csv(f\"/content/test.csv\")"
      ],
      "metadata": {
        "id": "q-6CgEWNWHdl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RuRWCSiVXL6n"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}