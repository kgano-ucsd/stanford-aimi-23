{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gqh0F-60baUC"
      },
      "source": [
        "## AIMI High School Internship 2023\n",
        "### Notebook 1: Extracting Labels from Radiology Reports\n",
        "\n",
        "**The Problem**: Given a chest X-ray, our goal in this project is to predict the distance from an endotracheal tube to the carina. This is an important clinical task - endotracheal tubes that are positioned too far (>5cm) above the carina will not work effectively.\n",
        "\n",
        "In order to train a model that can predict tube distances given chest X-rays, we require a ***training set*** with chest X-rays and labeled tube distances. However, when working with real-world medical data, important labels (e.g. endotracheal tube distances) are often not annotated ahead of time. The only data that a researcher has access to are the raw images and free-form clinical text written by the radiologist.\n",
        "\n",
        "**Your First Task**: Given a set of chest X-rays and paired radiology reports, your goal is to use natural language processing tools to extract endotracheal tube distances from the reports.\n",
        "\n",
        "**Looking Ahead**: When you complete this task, you should have a training dataset with chest X-rays labeled with endotracheal tube distances. You will later use this dataset to train a computer vision model that predicts the tube distance given an image."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_75WVQT-eRDT"
      },
      "source": [
        "### Load Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9jmHkNcxt5w"
      },
      "source": [
        "Upload `data.zip`. It should take about 10 minutes for these files to be uploaded. Then, run the following cells to unzip the dataset (which should take < 10 seconds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03dEuEHVeUYs"
      },
      "source": [
        "### Understanding the Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5765hi_9kSbE"
      },
      "source": [
        "Let's first go through some terminology. Medical data is often stored in a hierarchy consisting of three levels: patient, study, and images.\n",
        "- Patient: A patient is a single unique individual.\n",
        "- Study: Each patient may have multiple sets of images taken, perhaps on different days. Each set of images is referred to as a *study*.\n",
        "- Images: Each study consists of one or more *images*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVBKP0ZgpEa7"
      },
      "source": [
        "Chest X-ray images and radiology reports are stored in `data/` and are organized as follows:\n",
        "- `data/mimic-train`:\n",
        "  - Images: The MIMIC training set consists of 5313 subfolders, each representing a patient. Every patient has one or more studies, which are stored as subfolders. Images are stored in study folders as `.jpg` files with 512x512 pixels.\n",
        "  - Text: Reports are stored in patient folders with  `.txt` extensions. The filename corresponds to the study id and the content of the report applies to all images in the corresponding study.\n",
        "- `data/mimic-test`: The MIMIC test set is organized in a similar fashion as the MIMIC training set. Note that this is a held-out test set with 500 images that we will use for scoring models, so reports are not provided!\n",
        "- `data/mimic_train_student.csv`: This spreadsheet provides mappings between image paths, report paths, patient ids, study ids, and image ids for samples in the training set.\n",
        "- `data/mimic_test_student.csv`: This spreadsheet provides mappings between image paths, patient ids, study ids, and image ids for samples in the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "3NUgD5CAeXmU"
      },
      "outputs": [],
      "source": [
        "# Example Image\n",
        "from PIL import Image\n",
        "img = Image.open(f\"data/mimic-train/12000/59707/90529.jpg\")\n",
        "img.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "pM20ZAJYfrGI"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['                                 FINAL REPORT\\n',\n",
              " ' PORTABLE CHEST ___\\n',\n",
              " ' \\n',\n",
              " ' COMPARISON:  ___ radiograph.\\n',\n",
              " ' \\n',\n",
              " ' FINDINGS:  Tip of endotracheal tube terminates 6 cm above the carina. \\n',\n",
              " ' Cardiomediastinal contours are normal in appearance, and lungs are grossly\\n',\n",
              " ' clear.\\n']"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Example Text Report\n",
        "with open(f\"data/mimic-train/12000/59707.txt\", \"r\") as f:\n",
        "  txt = f.readlines()\n",
        "txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Ot-DSq6nzlsl"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>split</th>\n",
              "      <th>patient_id</th>\n",
              "      <th>study_id</th>\n",
              "      <th>image_id</th>\n",
              "      <th>image_path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>test</td>\n",
              "      <td>10345</td>\n",
              "      <td>50410</td>\n",
              "      <td>80276</td>\n",
              "      <td>mimic-test/10345/50410/80276.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>test</td>\n",
              "      <td>10345</td>\n",
              "      <td>50232</td>\n",
              "      <td>80350</td>\n",
              "      <td>mimic-test/10345/50232/80350.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>test</td>\n",
              "      <td>10189</td>\n",
              "      <td>50388</td>\n",
              "      <td>80353</td>\n",
              "      <td>mimic-test/10189/50388/80353.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>test</td>\n",
              "      <td>10127</td>\n",
              "      <td>50441</td>\n",
              "      <td>80124</td>\n",
              "      <td>mimic-test/10127/50441/80124.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>test</td>\n",
              "      <td>10004</td>\n",
              "      <td>50475</td>\n",
              "      <td>80218</td>\n",
              "      <td>mimic-test/10004/50475/80218.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>495</th>\n",
              "      <td>test</td>\n",
              "      <td>10252</td>\n",
              "      <td>50003</td>\n",
              "      <td>80193</td>\n",
              "      <td>mimic-test/10252/50003/80193.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>496</th>\n",
              "      <td>test</td>\n",
              "      <td>10363</td>\n",
              "      <td>50408</td>\n",
              "      <td>80072</td>\n",
              "      <td>mimic-test/10363/50408/80072.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>test</td>\n",
              "      <td>10363</td>\n",
              "      <td>50145</td>\n",
              "      <td>80039</td>\n",
              "      <td>mimic-test/10363/50145/80039.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498</th>\n",
              "      <td>test</td>\n",
              "      <td>10054</td>\n",
              "      <td>50265</td>\n",
              "      <td>80374</td>\n",
              "      <td>mimic-test/10054/50265/80374.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499</th>\n",
              "      <td>test</td>\n",
              "      <td>10058</td>\n",
              "      <td>50398</td>\n",
              "      <td>80032</td>\n",
              "      <td>mimic-test/10058/50398/80032.jpg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>500 rows Ã— 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    split  patient_id  study_id  image_id                        image_path\n",
              "0    test       10345     50410     80276  mimic-test/10345/50410/80276.jpg\n",
              "1    test       10345     50232     80350  mimic-test/10345/50232/80350.jpg\n",
              "2    test       10189     50388     80353  mimic-test/10189/50388/80353.jpg\n",
              "3    test       10127     50441     80124  mimic-test/10127/50441/80124.jpg\n",
              "4    test       10004     50475     80218  mimic-test/10004/50475/80218.jpg\n",
              "..    ...         ...       ...       ...                               ...\n",
              "495  test       10252     50003     80193  mimic-test/10252/50003/80193.jpg\n",
              "496  test       10363     50408     80072  mimic-test/10363/50408/80072.jpg\n",
              "497  test       10363     50145     80039  mimic-test/10363/50145/80039.jpg\n",
              "498  test       10054     50265     80374  mimic-test/10054/50265/80374.jpg\n",
              "499  test       10058     50398     80032  mimic-test/10058/50398/80032.jpg\n",
              "\n",
              "[500 rows x 5 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load csv file with mappings\n",
        "import pandas as pd\n",
        "subjects = pd.read_csv(f'data/mimic_test_student.csv')\n",
        "\n",
        "subjects = subjects.drop(columns=[\"Unnamed: 0\"])\n",
        "subjects\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqmARLEuhaGP"
      },
      "source": [
        "### Extracting Tube Distance Labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kwGvV1LZnfcq"
      },
      "source": [
        "You're now ready to begin this task! Keep in mind that not every chest X-ray provided in the training set contains endotracheal tube distance information, and there may be several edge cases to consider."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "TgeTSjDfheAX"
      },
      "outputs": [],
      "source": [
        "def is_cm(string):\n",
        "  valid = \"0123456789., \"\n",
        "  unit = None\n",
        "  for char in string:\n",
        "    if valid.find(char) == -1:\n",
        "      unit = char\n",
        "      break\n",
        "  return unit\n",
        "\n",
        "def validate(string):\n",
        "  valid = \"0123456789CcentiMmrl,. \"\n",
        "\n",
        "  for i, char in enumerate(string):\n",
        "    if valid.find(char) == -1:\n",
        "      return False\n",
        "  return True\n",
        "\n",
        "def handle_no_space(string):\n",
        "  valid = \"0123456789\"\n",
        "  end_of_int = 0\n",
        "\n",
        "  for i, char in enumerate(string):\n",
        "    if valid.find(char) == -1:\n",
        "      end_of_int = i - 1\n",
        "  return string[:end_of_int] + \".0\"\n",
        "\n",
        "def handle_space(string):\n",
        "  space_loc = string.find(\" \")\n",
        "  if space_loc != -1:\n",
        "      return string.split(\" \")[0] + \".0\"\n",
        "  return handle_no_space(string)\n",
        "\n",
        "def handle_period(string):\n",
        "  out = \"\"\n",
        "  valid = \"0123456789.\"\n",
        "  for i, char in enumerate(string):\n",
        "    if valid.find(char) != -1:\n",
        "      out += char\n",
        "  if out[len(out) - 1] == \".\":\n",
        "    out = out[:len(out) - 1]\n",
        "    return out\n",
        "  return out\n",
        "\n",
        "def parse_measure(measurement):\n",
        "  comma_loc = measurement.find(\",\")\n",
        "  period_loc = measurement.find(\".\")\n",
        "  # no comma or period\n",
        "  if period_loc == -1 and comma_loc == -1:\n",
        "    return handle_space(measurement)\n",
        "  # only a comma\n",
        "  if comma_loc != -1:\n",
        "    measurement = measurement.replace(\",\", \".\")\n",
        "  # at this point, all strings that made it\n",
        "  # this far have only a period\n",
        "  return handle_period(measurement)\n",
        "\n",
        "def parse_report(path):\n",
        "  with open(f\"data/{path}\", \"r\") as f:\n",
        "    txt = f.readlines()\n",
        "  return \"\".join(txt).replace(\"\\n\", \"\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5hpUKd6jsAa"
      },
      "source": [
        "## Measurement parsing test harness"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "2VPXSSd7ei3B"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n"
          ]
        }
      ],
      "source": [
        "# Test 1: 3.5 cm\n",
        "print(\"3.5\" == parse_measure(\"3.5 cm\"))\n",
        "# parse_measure(\"3.5 cm\")\n",
        "\n",
        "# Test 2: 3,5 cm\n",
        "print(\"3.5\" == parse_measure(\"3,5 cm\"))\n",
        "# parse_measure(\"3,5 cm\")\n",
        "\n",
        "# Test 3: 3 . 5 centimeter\n",
        "print(\"3.5\" == parse_measure(\"3 . 5 centimeter\"))\n",
        "# parse_measure(\"3 . 5 centimeter\")\n",
        "\n",
        "# Test 4: 3.5centimeters\n",
        "print(\"3.5\" == parse_measure(\"3.5centimeters\"))\n",
        "# parse_measure(\"3.5centimeters\")\n",
        "\n",
        "# Test 5: 3,5 centimetrs\n",
        "print(\"3.5\" == parse_measure(\"3,5 centimetrs\"))\n",
        "# parse_measure(\"3,5 centimetrs\")\n",
        "\n",
        "# Test 6: 3 cm\n",
        "print(\"3.0\" == parse_measure(\"3 cm\"))\n",
        "# parse_measure(\"3 cm\")\n",
        "\n",
        "# Test 7: 3.0 cm\n",
        "print(\"3.0\" == parse_measure(\"3.0 cm\"))\n",
        "# parse_measure(\"3.0 cm\")\n",
        "\n",
        "# Test 8: 12.5 cm\n",
        "print(\"12.5\" == parse_measure(\"12.5. cm\"))\n",
        "#print(parse_measure(\"12.5. cm\"))\n",
        "\n",
        "# Test 9: 22,5 cm\n",
        "print(\"22.5\" == parse_measure(\"22,5 cm\"))\n",
        "# parse_measure(\"3,5 cm\")\n",
        "\n",
        "# Test 10: 25 . 5 centimeter\n",
        "print(\"25.5\" == parse_measure(\"25 . 5 centimeter\"))\n",
        "# parse_measure(\"3 . 5 centimeter\")\n",
        "\n",
        "# Test 11: 361.5centimeters\n",
        "print(\"361.5\" == parse_measure(\"361.5centimeters\"))\n",
        "# parse_measure(\"3.5centimeters\")\n",
        "\n",
        "# Test 12: 46,5 centimetrs\n",
        "print(\"46.5\" == parse_measure(\"46,5 centimetrs\"))\n",
        "# parse_measure(\"3,5 centimetrs\")\n",
        "\n",
        "# Test 13: 75 cm\n",
        "print(\"75.0\" == parse_measure(\"75 cm\"))\n",
        "# parse_measure(\"3 cm\")\n",
        "\n",
        "# Test 14: 232.0 cm\n",
        "print(\"232.0\" == parse_measure(\"232.0 cm\"))\n",
        "# parse_measure(\"3.0 cm\")\n",
        "\n",
        "# Test 15: 232.0 cm\n",
        "print(\"232.0\" == parse_measure(\"2 3 2 .    0 cm\"))\n",
        "# parse_measure(\"3.0 cm\")\n",
        "\n",
        "# Test 16: 232 mm\n",
        "print(\"m\" == is_cm(\"232 mm\"))\n",
        "\n",
        "# Test 17: 232.0 millimietr\n",
        "print(\"m\" == is_cm(\"232.0 millimietr\"))\n",
        "\n",
        "# Test 18: 257 , 0 cm\n",
        "print(\"c\" == is_cm(\"257 , 0 cm\"))\n",
        "\n",
        "# Test 19: 25 , 0 cm\n",
        "print(\"c\" == is_cm(\"257 , 0 cm\"))\n",
        "\n",
        "# Test 20: 25\n",
        "print(None == is_cm(\"25\"))\n",
        "\n",
        "# Test 21: 2 and 3 cm\n",
        "print(False == validate(\"2 and 3 cm\"))\n",
        "\n",
        "# Test 22: 2 or 3 cm\n",
        "print(False == validate(\"2 or 3 cm\"))\n",
        "\n",
        "# Test 23: 2-3 cm\n",
        "print(False == validate(\"2-3 cm\"))\n",
        "\n",
        "# Test 24: less than 2 cm:\n",
        "print(False == validate(\"less than 2 cm\"))\n",
        "\n",
        "# Test 25: 2 away\n",
        "print(False == validate(\"2 away\"))\n",
        "\n",
        "# Test 26:\n",
        "print(True == validate(\"2 3 2 .    0 cm\"))\n",
        "\n",
        "# Test 27:\n",
        "print(True == validate(\"25 . 5 centimeter\"))\n",
        "\n",
        "# Test 28:\n",
        "print(True == validate(\"22,5 cm\"))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "tPFfGRZ3k3FC"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/miniconda3/envs/pyro/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "from transformers import AutoTokenizer, AutoModelForTokenClassification, AutoModelForQuestionAnswering\n",
        "\n",
        " # pass device=0 if using gpu\n",
        "\n",
        "def biomed_token_class(report):\n",
        "  tokenizer = AutoTokenizer.from_pretrained(\"d4data/biomedical-ner-all\")\n",
        "  model = AutoModelForTokenClassification.from_pretrained(\"d4data/biomedical-ner-all\")\n",
        "  pipe = pipeline(\"ner\", model=model, tokenizer=tokenizer, aggregation_strategy=\"simple\")\n",
        "  return pipe(report)\n",
        "\n",
        "def roberta_squad2(report):\n",
        "  question = \"What is the exact distance between the ETT device and the carina?\"\n",
        "\n",
        "  model_name = \"deepset/roberta-base-squad2\"\n",
        "  model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
        "  tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "  pipe = pipeline('question-answering', model=model, tokenizer=tokenizer)\n",
        "\n",
        "  qa_input = {\n",
        "      'question': question,\n",
        "      'context': report\n",
        "  }\n",
        "\n",
        "  return pipe(qa_input)['answer']\n",
        "\n",
        "def get_distance(report):\n",
        "  measure_roberta = roberta_squad2(report)\n",
        "  roberta_valid = validate(measure_roberta)\n",
        "  if not roberta_valid:\n",
        "    return \"-1\"\n",
        "  if roberta_valid and is_cm(measure_roberta) is not None:\n",
        "    return measure_roberta\n",
        "  return \"-2\"\n",
        "\n",
        "def get_biomed_token_class(report):\n",
        "  response = biomed_token_class(report)\n",
        "  measure = \"-1\"\n",
        "  max_score = 0\n",
        "  for json in response:\n",
        "    if json[\"entity_group\"] == \"Distance\" and json[\"score\"] > max_score:\n",
        "      measure = json[\"word\"]\n",
        "      max_score = json[\"score\"]\n",
        "  return measure\n",
        "\n",
        "NOT_VALID = -1.0\n",
        "NO_UNITS = -2.0\n",
        "\n",
        "def process_volume(path):\n",
        "  report = parse_report(path)\n",
        "  distance = get_distance(report)\n",
        "  if distance == \"-1\":\n",
        "    return NOT_VALID\n",
        "  if distance == \"-2\":\n",
        "    return NO_UNITS\n",
        "  unit = is_cm(distance)\n",
        "  measurement = parse_measure(distance)\n",
        "  if unit == \"m\" or unit == \"M\":\n",
        "    return float(measurement) / 10.0\n",
        "  return float(measurement)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "d8j6QhxjgTqd"
      },
      "outputs": [],
      "source": [
        "\n",
        "def good_positioning(measure):\n",
        "  if measure < 0:\n",
        "    return -1\n",
        "  if measure <= 5:\n",
        "    return 1\n",
        "  return 0\n",
        "\n",
        "\n",
        "# Load csv file with mappings\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def get_labels(data):\n",
        "  PATH = f\"data/mimic_{data}_student.csv\"\n",
        "  subjects = pd.read_csv(PATH)\n",
        "  subjects = subjects.drop(columns=[\"Unnamed: 0\", \"study_id\", \"image_id\"])\n",
        "  report_paths = subjects[\"report_path\"].to_numpy()\n",
        "  measures = []\n",
        "  positioning = [] # 1 is good, 0 is bad\n",
        "\n",
        "  for i, path in enumerate(report_paths):\n",
        "    if i % 100 == 0:\n",
        "      print(f\"Progress checkpoint, processed {i} volumes. {len(report_paths) - (i)} remain.\")\n",
        "    if i % 1000 == 0:\n",
        "      print(f\"Saving {i} data points to data/batch-{i}.csv\")\n",
        "      checkpoint = pd.DataFrame()\n",
        "      checkpoint[\"measures\"] = measures\n",
        "      checkpoint[\"positioning\"] = positioning\n",
        "      checkpoint.to_csv(f\"data/batch-{i}.csv\")\n",
        "\n",
        "    measure = process_volume(path)\n",
        "    measures.append(measure)\n",
        "    positioning.append(good_positioning(measure))\n",
        "\n",
        "  subjects[\"measures\"] = measures\n",
        "  subjects[\"positioning\"] = positioning\n",
        "  subjects.to_csv(f\"data/mimic_{data}_labels.csv\")\n",
        "\n",
        "# get_labels(data=\"train\")\n",
        "# print(\"Task completed.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of volumes with invalid text files: 667\n",
            "Number of volumes with no units: 13\n",
            "Total number of problematic volumes: 680\n"
          ]
        }
      ],
      "source": [
        "raw_labels = pd.read_csv(f\"mimic_train_labels.csv\")\n",
        "num_problems = len(np.where(raw_labels[\"measures\"].to_numpy() < 0)[0])\n",
        "\n",
        "num_not_valid = len(np.where(raw_labels[\"measures\"].to_numpy() == -1.0)[0])\n",
        "num_no_units = len(np.where(raw_labels[\"measures\"].to_numpy() == -2.0)[0])\n",
        "\n",
        "# These are images without endotracheal devices\n",
        "print(f\"Number of volumes with invalid text files: {num_not_valid}\")\n",
        "# Delete these rows\n",
        "print(f\"Number of volumes with no units: {num_no_units}\")\n",
        "print(f\"Total number of problematic volumes: {num_problems}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of volumes with invalid text files: 0\n",
            "Number of volumes with no units: 0\n",
            "Total number of problematic volumes: 0\n",
            "Total number of data points that remain: (11565,)\n"
          ]
        }
      ],
      "source": [
        "# Prune data\n",
        "pruned = raw_labels[raw_labels.measures > -1.0]\n",
        "\n",
        "pruned.to_csv(\"mimic_train_labels_pruned.csv\")\n",
        "\n",
        "new = pd.read_csv(f\"mimic_train_labels_pruned.csv\")\n",
        "num_problems = len(np.where(new[\"measures\"].to_numpy() < 0)[0])\n",
        "\n",
        "num_not_valid = len(np.where(new[\"measures\"].to_numpy() == -1.0)[0])\n",
        "num_no_units = len(np.where(new[\"measures\"].to_numpy() == -2.0)[0])\n",
        "\n",
        "# These are images without endotracheal devices\n",
        "print(f\"Number of volumes with invalid text files: {num_not_valid}\")\n",
        "# Delete these rows\n",
        "print(f\"Number of volumes with no units: {num_no_units}\")\n",
        "print(f\"Total number of problematic volumes: {num_problems}\")\n",
        "print(f\"Total number of data points that remain: {new['measures'].to_numpy().shape}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
