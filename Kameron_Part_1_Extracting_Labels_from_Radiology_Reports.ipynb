{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gqh0F-60baUC"
      },
      "source": [
        "## AIMI High School Internship 2023\n",
        "### Notebook 1: Extracting Labels from Radiology Reports\n",
        "\n",
        "**The Problem**: Given a chest X-ray, our goal in this project is to predict the distance from an endotracheal tube to the carina. This is an important clinical task - endotracheal tubes that are positioned too far (>5cm) above the carina will not work effectively.\n",
        "\n",
        "In order to train a model that can predict tube distances given chest X-rays, we require a ***training set*** with chest X-rays and labeled tube distances. However, when working with real-world medical data, important labels (e.g. endotracheal tube distances) are often not annotated ahead of time. The only data that a researcher has access to are the raw images and free-form clinical text written by the radiologist.\n",
        "\n",
        "**Your First Task**: Given a set of chest X-rays and paired radiology reports, your goal is to use natural language processing tools to extract endotracheal tube distances from the reports.\n",
        "\n",
        "**Looking Ahead**: When you complete this task, you should have a training dataset with chest X-rays labeled with endotracheal tube distances. You will later use this dataset to train a computer vision model that predicts the tube distance given an image."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_75WVQT-eRDT"
      },
      "source": [
        "### Load Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9jmHkNcxt5w"
      },
      "source": [
        "Upload `data.zip`. It should take about 10 minutes for these files to be uploaded. Then, run the following cells to unzip the dataset (which should take < 10 seconds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03dEuEHVeUYs"
      },
      "source": [
        "### Understanding the Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5765hi_9kSbE"
      },
      "source": [
        "Let's first go through some terminology. Medical data is often stored in a hierarchy consisting of three levels: patient, study, and images.\n",
        "- Patient: A patient is a single unique individual.\n",
        "- Study: Each patient may have multiple sets of images taken, perhaps on different days. Each set of images is referred to as a *study*.\n",
        "- Images: Each study consists of one or more *images*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVBKP0ZgpEa7"
      },
      "source": [
        "Chest X-ray images and radiology reports are stored in `data/` and are organized as follows:\n",
        "- `data/mimic-train`:\n",
        "  - Images: The MIMIC training set consists of 5313 subfolders, each representing a patient. Every patient has one or more studies, which are stored as subfolders. Images are stored in study folders as `.jpg` files with 512x512 pixels.\n",
        "  - Text: Reports are stored in patient folders with  `.txt` extensions. The filename corresponds to the study id and the content of the report applies to all images in the corresponding study.\n",
        "- `data/mimic-test`: The MIMIC test set is organized in a similar fashion as the MIMIC training set. Note that this is a held-out test set with 500 images that we will use for scoring models, so reports are not provided!\n",
        "- `data/mimic_train_student.csv`: This spreadsheet provides mappings between image paths, report paths, patient ids, study ids, and image ids for samples in the training set.\n",
        "- `data/mimic_test_student.csv`: This spreadsheet provides mappings between image paths, patient ids, study ids, and image ids for samples in the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dD_8kh5GL0oH"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "EXTENSION = \"drive/MyDrive/aimi_mimic_subset\"\n",
        "\n",
        "!unzip -qq /content/drive/MyDrive/kams_colab/mimic-train.zip\n",
        "!unzip -qq /content/drive/MyDrive/kams_colab/mimic-test.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3NUgD5CAeXmU"
      },
      "outputs": [],
      "source": [
        "# Example Image\n",
        "from PIL import Image\n",
        "img = Image.open(f\"/content/mimic-train/12000/59707/90529.jpg\")\n",
        "img.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pM20ZAJYfrGI"
      },
      "outputs": [],
      "source": [
        "# Example Text Report\n",
        "with open(f\"/content/mimic-train/12000/59707.txt\", \"r\") as f:\n",
        "  txt = f.readlines()\n",
        "txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ot-DSq6nzlsl"
      },
      "outputs": [],
      "source": [
        "# Load csv file with mappings\n",
        "import pandas as pd\n",
        "subjects = pd.read_csv(f'drive/MyDrive/kams_colab/mimic_test_student.csv')\n",
        "\n",
        "subjects = subjects.drop(columns=[\"Unnamed: 0\"])\n",
        "subjects\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqmARLEuhaGP"
      },
      "source": [
        "### Extracting Tube Distance Labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kwGvV1LZnfcq"
      },
      "source": [
        "You're now ready to begin this task! Keep in mind that not every chest X-ray provided in the training set contains endotracheal tube distance information, and there may be several edge cases to consider."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0rhU35IDhdAf"
      },
      "outputs": [],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TgeTSjDfheAX"
      },
      "outputs": [],
      "source": [
        "def is_cm(string):\n",
        "  valid = \"0123456789., \"\n",
        "  unit = None\n",
        "  for char in string:\n",
        "    if valid.find(char) == -1:\n",
        "      unit = char\n",
        "      break\n",
        "  return unit\n",
        "\n",
        "def validate(string):\n",
        "  valid = \"0123456789CcentiMmrl,. \"\n",
        "\n",
        "  for i, char in enumerate(string):\n",
        "    if valid.find(char) == -1:\n",
        "      return False\n",
        "  return True\n",
        "\n",
        "def handle_no_space(string):\n",
        "  valid = \"0123456789\"\n",
        "  end_of_int = 0\n",
        "\n",
        "  for i, char in enumerate(string):\n",
        "    if valid.find(char) == -1:\n",
        "      end_of_int = i - 1\n",
        "  return string[:end_of_int] + \".0\"\n",
        "\n",
        "def handle_space(string):\n",
        "  space_loc = string.find(\" \")\n",
        "  if space_loc != -1:\n",
        "      return string.split(\" \")[0] + \".0\"\n",
        "  return handle_no_space(string)\n",
        "\n",
        "def handle_period(string):\n",
        "  out = \"\"\n",
        "  valid = \"0123456789.\"\n",
        "  for i, char in enumerate(string):\n",
        "    if valid.find(char) != -1:\n",
        "      out += char\n",
        "\n",
        "  return out\n",
        "\n",
        "def parse_measure(measurement):\n",
        "  comma_loc = measurement.find(\",\")\n",
        "  period_loc = measurement.find(\".\")\n",
        "  # no comma or period\n",
        "  if period_loc == -1 and comma_loc == -1:\n",
        "    return handle_space(measurement)\n",
        "  # only a comma\n",
        "  if comma_loc != -1:\n",
        "    measurement = measurement.replace(\",\", \".\")\n",
        "  # at this point, all strings that made it\n",
        "  # this far have only a period\n",
        "  return handle_period(measurement)\n",
        "\n",
        "def parse_report(path):\n",
        "  with open(f\"/content/{path}\", \"r\") as f:\n",
        "    txt = f.readlines()\n",
        "  return \"\".join(txt).replace(\"\\n\", \"\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5hpUKd6jsAa"
      },
      "source": [
        "## Measurement parsing test harness"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2VPXSSd7ei3B"
      },
      "outputs": [],
      "source": [
        "# Test 1: 3.5 cm\n",
        "print(\"3.5\" == parse_measure(\"3.5 cm\"))\n",
        "# parse_measure(\"3.5 cm\")\n",
        "\n",
        "# Test 2: 3,5 cm\n",
        "print(\"3.5\" == parse_measure(\"3,5 cm\"))\n",
        "# parse_measure(\"3,5 cm\")\n",
        "\n",
        "# Test 3: 3 . 5 centimeter\n",
        "print(\"3.5\" == parse_measure(\"3 . 5 centimeter\"))\n",
        "# parse_measure(\"3 . 5 centimeter\")\n",
        "\n",
        "# Test 4: 3.5centimeters\n",
        "print(\"3.5\" == parse_measure(\"3.5centimeters\"))\n",
        "# parse_measure(\"3.5centimeters\")\n",
        "\n",
        "# Test 5: 3,5 centimetrs\n",
        "print(\"3.5\" == parse_measure(\"3,5 centimetrs\"))\n",
        "# parse_measure(\"3,5 centimetrs\")\n",
        "\n",
        "# Test 6: 3 cm\n",
        "print(\"3.0\" == parse_measure(\"3 cm\"))\n",
        "# parse_measure(\"3 cm\")\n",
        "\n",
        "# Test 7: 3.0 cm\n",
        "print(\"3.0\" == parse_measure(\"3.0 cm\"))\n",
        "# parse_measure(\"3.0 cm\")\n",
        "\n",
        "# Test 8: 12.5 cm\n",
        "print(\"12.5\" == parse_measure(\"12.5. cm\"))\n",
        "# parse_measure(\"3.5 cm\")\n",
        "\n",
        "# Test 9: 22,5 cm\n",
        "print(\"22.5\" == parse_measure(\"22,5 cm\"))\n",
        "# parse_measure(\"3,5 cm\")\n",
        "\n",
        "# Test 10: 25 . 5 centimeter\n",
        "print(\"25.5\" == parse_measure(\"25 . 5 centimeter\"))\n",
        "# parse_measure(\"3 . 5 centimeter\")\n",
        "\n",
        "# Test 11: 361.5centimeters\n",
        "print(\"361.5\" == parse_measure(\"361.5centimeters\"))\n",
        "# parse_measure(\"3.5centimeters\")\n",
        "\n",
        "# Test 12: 46,5 centimetrs\n",
        "print(\"46.5\" == parse_measure(\"46,5 centimetrs\"))\n",
        "# parse_measure(\"3,5 centimetrs\")\n",
        "\n",
        "# Test 13: 75 cm\n",
        "print(\"75.0\" == parse_measure(\"75 cm\"))\n",
        "# parse_measure(\"3 cm\")\n",
        "\n",
        "# Test 14: 232.0 cm\n",
        "print(\"232.0\" == parse_measure(\"232.0 cm\"))\n",
        "# parse_measure(\"3.0 cm\")\n",
        "\n",
        "# Test 15: 232.0 cm\n",
        "print(\"232.0\" == parse_measure(\"2 3 2 .    0 cm\"))\n",
        "# parse_measure(\"3.0 cm\")\n",
        "\n",
        "# Test 16: 232 mm\n",
        "print(\"m\" == is_cm(\"232 mm\"))\n",
        "\n",
        "# Test 17: 232.0 millimietr\n",
        "print(\"m\" == is_cm(\"232.0 millimietr\"))\n",
        "\n",
        "# Test 18: 257 , 0 cm\n",
        "print(\"c\" == is_cm(\"257 , 0 cm\"))\n",
        "\n",
        "# Test 19: 25 , 0 cm\n",
        "print(\"c\" == is_cm(\"257 , 0 cm\"))\n",
        "\n",
        "# Test 20: 25\n",
        "print(None == is_cm(\"25\"))\n",
        "\n",
        "# Test 21: 2 and 3 cm\n",
        "print(False == validate(\"2 and 3 cm\"))\n",
        "\n",
        "# Test 22: 2 or 3 cm\n",
        "print(False == validate(\"2 or 3 cm\"))\n",
        "\n",
        "# Test 23: 2-3 cm\n",
        "print(False == validate(\"2-3 cm\"))\n",
        "\n",
        "# Test 24: less than 2 cm:\n",
        "print(False == validate(\"less than 2 cm\"))\n",
        "\n",
        "# Test 25: 2 away\n",
        "print(False == validate(\"2 away\"))\n",
        "\n",
        "# Test 26:\n",
        "print(True == validate(\"2 3 2 .    0 cm\"))\n",
        "\n",
        "# Test 27:\n",
        "print(True == validate(\"25 . 5 centimeter\"))\n",
        "\n",
        "# Test 28:\n",
        "print(True == validate(\"22,5 cm\"))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tPFfGRZ3k3FC"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "from transformers import AutoTokenizer, AutoModelForTokenClassification, AutoModelForQuestionAnswering\n",
        "\n",
        " # pass device=0 if using gpu\n",
        "\n",
        "def biomed_token_class(report):\n",
        "  tokenizer = AutoTokenizer.from_pretrained(\"d4data/biomedical-ner-all\")\n",
        "  model = AutoModelForTokenClassification.from_pretrained(\"d4data/biomedical-ner-all\")\n",
        "  pipe = pipeline(\"ner\", model=model, tokenizer=tokenizer, aggregation_strategy=\"simple\")\n",
        "  return pipe(report)\n",
        "\n",
        "def roberta_squad2(report):\n",
        "  question = \"What is the exact distance between the ETT device and the carina?\"\n",
        "\n",
        "  model_name = \"deepset/roberta-base-squad2\"\n",
        "  model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
        "  tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "  pipe = pipeline('question-answering', model=model, tokenizer=tokenizer)\n",
        "\n",
        "  qa_input = {\n",
        "      'question': question,\n",
        "      'context': report\n",
        "  }\n",
        "\n",
        "  return pipe(qa_input)['answer']\n",
        "\n",
        "# def get_distance(report):\n",
        "#   measure_tkn_class = get_biomed_token_class(report)\n",
        "#   measure_roberta = roberta_squad2(report)\n",
        "\n",
        "#   tkn_class_valid = validate(measure_tkn_class)\n",
        "#   roberta_valid = validate(measure_roberta)\n",
        "#   if not tkn_class_valid and not roberta_valid:\n",
        "#     return \"-1\"\n",
        "#   if tkn_class_valid and is_cm(measure_tkn_class) is not None:\n",
        "#     return measure_tkn_class\n",
        "#   if roberta_valid and is_cm(measure_roberta) is not None:\n",
        "#     return measure_roberta\n",
        "#   return \"-2\"\n",
        "\n",
        "def get_distance(report):\n",
        "  measure_roberta = roberta_squad2(report)\n",
        "  roberta_valid = validate(measure_roberta)\n",
        "  if not roberta_valid:\n",
        "    return \"-1\"\n",
        "  if roberta_valid and is_cm(measure_roberta) is not None:\n",
        "    return measure_roberta\n",
        "  return \"-2\"\n",
        "\n",
        "def get_biomed_token_class(report):\n",
        "  response = biomed_token_class(report)\n",
        "  measure = \"-1\"\n",
        "  max_score = 0\n",
        "  for json in response:\n",
        "    if json[\"entity_group\"] == \"Distance\" and json[\"score\"] > max_score:\n",
        "      measure = json[\"word\"]\n",
        "      max_score = json[\"score\"]\n",
        "  return measure\n",
        "\n",
        "NOT_VALID = -1.0\n",
        "NO_UNITS = -2.0\n",
        "\n",
        "def process_volume(path):\n",
        "  report = parse_report(path)\n",
        "  distance = get_distance(report)\n",
        "  if distance == \"-1\":\n",
        "    return NOT_VALID\n",
        "  if distance == \"-2\":\n",
        "    return NO_UNITS\n",
        "  unit = is_cm(distance)\n",
        "  measurement = parse_measure(distance)\n",
        "  if unit == \"m\" or unit == \"M\":\n",
        "    return float(measurement) / 10.0\n",
        "  return float(measurement)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d8j6QhxjgTqd"
      },
      "outputs": [],
      "source": [
        "PATH_TO_TRAIN = \"drive/MyDrive/Colab Notebooks/mimic_train_student.csv\"\n",
        "PATH_TO_TEST = \"drive/MyDrive/Colab Notebooks/mimic_test_student.csv\"\n",
        "\n",
        "def good_positioning(measure):\n",
        "  if measure < 0:\n",
        "    return -1\n",
        "  if measure <= 5:\n",
        "    return 1\n",
        "  return 0\n",
        "\n",
        "\n",
        "# Load csv file with mappings\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def get_labels(data):\n",
        "  PATH = f\"drive/MyDrive/kams_colab/mimic_{data}_student.csv\"\n",
        "  subjects = pd.read_csv(PATH)\n",
        "  subjects = subjects.drop(columns=[\"Unnamed: 0\", \"study_id\", \"image_id\"])\n",
        "  report_paths = subjects[\"report_path\"].to_numpy()\n",
        "  measures = []\n",
        "  positioning = [] # 1 is good, 0 is bad\n",
        "\n",
        "  for i, path in enumerate(report_paths):\n",
        "    if i % 100 == 0:\n",
        "      print(f\"Progress checkpoint, processed {i} volumes. {len(report_paths) - (i)} remain.\")\n",
        "    measure = process_volume(path)\n",
        "    measures.append(measure)\n",
        "    positioning.append(good_positioning(measure))\n",
        "  subjects[\"measures\"] = measures\n",
        "  subjects[\"positioning\"] = positioning\n",
        "\n",
        "  subjects.to_csv(f\"drive/MyDrive/kams_colab/mimic_{data}_labels.csv\")\n",
        "\n",
        "get_labels(data=\"train\")\n",
        "print(\"Task completed.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}